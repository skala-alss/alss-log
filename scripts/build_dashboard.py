#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ALSS Dashboard Builder (solved.ac + Git repo)
- Week README: ONLY update member columns (#1..#N)
  DURING: solved_by & repo(main or any branch) has member file
  PRE   : solved_by & no member file in repo
  NONE  : not solved_by
  * Old filename rule supported: week root: boj_{pid}_{member}.ext
  * Also supports {member}_{pid}(_N)?.ext and any path containing boj_{pid}
- Root README:
  1) ì£¼ì°¨ë³„ ì™„ë£Œìœ¨(ë°°ì •ì„¸íŠ¸ ê¸°ì¤€, **DURINGë§Œ ì§‘ê³„**)
  2) ì „ì²´ ë¦¬ë”ë³´ë“œ(ë™ì¼, **DURINGë§Œ ì§‘ê³„**)
  3) ë©¤ë²„ë³„ ì£¼ì°¨ë³„ ëˆ„ì  ì¶”ì„¸(ì œì¶œ ì£¼ì°¨ ê·€ì† / **ë°°ì • ëˆ„ì  ë¶„ëª¨**, %)
     - ë³‘í•© PR: "submit: weekNN-<alias>" ì»¤ë°‹ì˜ ë³€ê²½ íŒŒì¼
     - ë¯¸ë³‘í•© ë¸Œëœì¹˜: (ë³´ì¡°) git diff main...<branch> ì˜ ë³€ê²½ íŒŒì¼
     - í´ë°±: ALSS_TREND_FALLBACK_DURING=1 ì´ë©´ DURINGì„ ë°°ì • ì£¼ì°¨ë¡œ ê·€ì†
     - âœ¨ ëˆ„ì  ì¶”ì„¸ ë¶„ì/ë¶„ëª¨ ì¼ì¹˜: **ë¶„ìë„ ë°°ì • ì„¸íŠ¸ ë‚´ PIDë§Œ** ì§‘ê³„
NOTE: released_at ì†ì„±ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ.

Env:
  ALSS_OVERWRITE=1               # overwrite all member cells (default: 1; 0ì´ë©´ ë¹ˆì¹¸ë§Œ ì±„ì›€)
  ALSS_CHECK_BRANCHES=1          # scan all refs/heads + refs/remotes (default: 1)
  ALSS_DEBUG=1                   # debug logs (default: 1)
  ALSS_TREND_FALLBACK_DURING=0   # trend ê·€ì† í´ë°±(ë°°ì • ì£¼ì°¨ë¡œ) í™œì„±í™” (default: 0)
  ALSS_LOG_LIMIT=0               # (ì„ íƒ) ì»¤ë°‹ ìŠ¤ìº” ìƒí•œ(-n). 0 ë˜ëŠ” ë¯¸ì§€ì •ì´ë©´ ë¬´ì œí•œ
"""

import os, re, time, math, subprocess, shlex, unicodedata
from typing import Dict, List, Set, Tuple
import requests, yaml

# ---------- Paths ----------
ROOT_DIR = os.path.dirname(os.path.dirname(__file__))
CONFIG_DIR = os.path.join(ROOT_DIR, "config")

PARTICIPANTS_YAML = os.path.join(CONFIG_DIR, "participants.yaml")
WEEKS_YAML = os.path.join(CONFIG_DIR, "weeks.yaml")
ROOT_README = os.path.join(ROOT_DIR, "README.md")

# ---------- Env ----------
OVERWRITE_ALL_MEMBER_CELLS = os.getenv("ALSS_OVERWRITE", "1") == "1"
CHECK_BRANCHES = os.getenv("ALSS_CHECK_BRANCHES", "1") == "1"
DEBUG = os.getenv("ALSS_DEBUG", "1") == "1"
ALSS_TREND_FALLBACK_DURING = os.getenv("ALSS_TREND_FALLBACK_DURING", "0") == "1"

# ---------- solved.ac API ----------
SOLVED_BASE = "https://solved.ac/api/v3"
SESSION = requests.Session()
SESSION.headers.update({
    "User-Agent": "alss-dashboard/2.2 (+https://github.com/your/repo)",
})

def _get(url, params=None, max_retry=5):
    for _ in range(max_retry):
        r = SESSION.get(url, params=params, timeout=30)
        if r.status_code == 429:
            retry_after = int(r.headers.get("Retry-After", "3") or "3")
            time.sleep(max(3, retry_after))
            continue
        r.raise_for_status()
        time.sleep(0.25)  # gentle rate limit
        return r.json()
    raise RuntimeError(f"Too many 429s for {url} {params}")

def solved_search_problem(query: str, page: int = 1) -> dict:
    return _get(f"{SOLVED_BASE}/search/problem", params={"query": query, "page": page})

def solved_set(handle: str, restrict_ids: Set[int] = None) -> Set[int]:
    """solved_by:<handle> (no date) â†’ problemId set, restricted to given IDs."""
    q = f"solved_by:{handle}"
    got: Set[int] = set()
    page = 1
    while True:
        data = solved_search_problem(q, page=page)
        items = data.get("items", [])
        for it in items:
            pid = it["problemId"]
            if (restrict_ids is None) or (pid in restrict_ids):
                got.add(pid)
        count = data.get("count", 0)
        total_pages = max(1, math.ceil(count / 50))
        if page >= total_pages or not items:
            break
        page += 1
    return got

# ---------- IO ----------
def load_yaml(path: str):
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)

def read_file(path: str) -> str:
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

def write_if_changed(path: str, new_text: str) -> bool:
    old = read_file(path) if os.path.exists(path) else ""
    if old != new_text:
        with open(path, "w", encoding="utf-8") as f:
            f.write(new_text)
        return True
    return False

# ---------- Markdown utils (patch member columns only) ----------
SYMBOL = {"PRE": "â˜‘ï¸", "DURING": "âœ…", "NONE": "âŒ"}

def is_blank_cell(val: str) -> bool:
    v = (val or "").strip().replace("&nbsp;", "")
    return v == ""

def _get_block(text: str, marker: str) -> Tuple[str, int, int]:
    start = f"<!--START:{marker}-->"
    end   = f"<!--END:{marker}-->"
    s = re.search(re.escape(start), text)
    e = re.search(re.escape(end), text)
    if not s or not e or s.end() >= e.start():
        return "", -1, -1
    return text[s.end():e.start()], s.start(), e.end()

def _split_row(line: str) -> List[str]:
    if not line.strip().startswith("|"):
        return []
    return [c.strip() for c in line.strip().strip("|").split("|")]

def _join_row(cells: List[str]) -> str:
    return "| " + " | ".join(cells) + " |"

def _is_separator_row(cells: List[str]) -> bool:
    return all(re.match(r"^:?-{3,}:?$", c.strip()) or c.strip() == "" for c in cells)

def _find_col_idx(header_cells, exact, fuzzy):
    for key in exact:
        if key in header_cells:
            return header_cells.index(key)
    for i, c in enumerate(header_cells):
        cc = c.strip().lower()
        if any(fz in cc for fz in fuzzy):
            return i
    raise ValueError("column not found")

def patch_member_columns_in_block(block_md, pid_to_states, participants):
    lines = block_md.strip("\n").splitlines()
    if len(lines) < 2:
        return block_md

    # í‘œ í—¤ë” ì°¾ê¸°
    header_idx = None
    for i, ln in enumerate(lines):
        if ln.strip().startswith("|"):
            header_idx = i
            break
    if header_idx is None or header_idx + 1 >= len(lines):
        if DEBUG:
            print("[debug] header not found in block")
        return block_md

    header = _split_row(lines[header_idx])

    try:
        folder_col = _find_col_idx(header, exact=["í´ë”"], fuzzy=["í´ë”", "folder", "ğŸ“"])
        number_col = _find_col_idx(header, exact=["ë²ˆí˜¸"], fuzzy=["ë²ˆí˜¸", "no", "id"])
    except ValueError:
        if DEBUG:
            print(f"[debug] header parse failed: {header}")
        return block_md

    member_cols = list(range(folder_col + 1, len(header)))
    seats = [m["seat"] for m in participants]
    data_start = header_idx + 2  # header + separator

    for i in range(data_start, len(lines)):
        cells = _split_row(lines[i])
        if not cells or _is_separator_row(cells):
            continue

        # ë¬¸ì œ ë²ˆí˜¸
        try:
            pid = int(re.sub(r"[^\d]", "", cells[number_col]))
        except ValueError:
            continue
        if pid not in pid_to_states:
            continue

        # ë©¤ë²„ ì¹¸ ë®ì–´ì“°ê¸°
        for idx, seat in enumerate(seats):
            col = member_cols[idx]
            state = pid_to_states[pid].get(str(seat), "NONE")
            sym = SYMBOL.get(state, SYMBOL["NONE"])
            if cells[col] != sym:
                if DEBUG:
                    print(f"[debug] patch: pid={pid} seat={seat} state={state} -> '{sym}' (was '{cells[col]}')")
                cells[col] = sym
            else:
                if DEBUG:
                    print(f"[debug] patch: pid={pid} seat={seat} state={state} (no change)")
        lines[i] = _join_row(cells)

    return "\n".join(lines)

def _replace_block_exact(text: str, marker: str, new_md_inside: str, s: int, e: int) -> str:
    return text[:s] + f"<!--START:{marker}-->\n\n{new_md_inside}\n\n<!--END:{marker}-->" + text[e:]

def render_week_readme_members_only(week_cfg, participants, states_by_group):
    # 1) ìƒëŒ€ ê²½ë¡œ ì›ë³¸ì„ ë¨¼ì € í™•ì¸
    rel = (week_cfg.get("path") or "").strip()
    if not rel:
        if DEBUG:
            print(f"[debug] skip week README (empty path): id={week_cfg.get('id')}")
        return False

    # 2) ì ˆëŒ€ ê²½ë¡œ ë§Œë“¤ê³  'íŒŒì¼'ì¸ì§€ í™•ì¸
    path = os.path.join(ROOT_DIR, rel)
    if not os.path.isfile(path):  # ë””ë ‰í„°ë¦¬/ë¯¸ì¡´ì¬ ëª¨ë‘ ìŠ¤í‚µ
        if DEBUG:
            print(f"[debug] skip week README (not a file): {path}")
        return False

    try:
        text = read_file(path)
    except Exception as e:
        if DEBUG:
            print(f"[debug] skip week README (read error): {path} ({e})")
        return False
    changed = False

    for g in week_cfg["groups"]:
        marker = g.get("marker") or f"PROGRESS:{g['key']}"
        block, s, e = _get_block(text, marker)
        if s == -1:
            if DEBUG:
                print(f"[debug] no block found for marker='{marker}' in {path}")
            continue

        new_block = patch_member_columns_in_block(block.strip("\n"),
                                                  states_by_group[g["key"]],
                                                  participants)

        if new_block != block.strip("\n"):
            if DEBUG:
                print(f"[debug] block changed: {marker} in {path}")
            text = _replace_block_exact(text, marker, new_block, s, e)
            changed = True
        else:
            if DEBUG:
                print(f"[debug] block unchanged: {marker} in {path}")

    if changed:
        write_if_changed(path, text)
    return changed

# ---------- Member / Path matching ----------
ALLOWED_EXT = {".cpp",".cc",".cxx",".c",".py",".java",".kt",".js",".ts",
               ".rb",".go",".cs",".swift",".rs",".m",".mm"}

def _norm_token(s: str) -> str:
    # í•œê¸€/ê¸°í˜¸ ê²½ë¡œì˜ ì •ê·œí™” ë¬¸ì œë¥¼ ì—†ì• ê¸° ìœ„í•´ NFKC ì ìš©
    s = unicodedata.normalize("NFKC", (s or ""))
    return re.sub(r"[\s_\-]+", "_", s.strip().lower())

def _member_keys_for_match(m: dict) -> List[str]:
    keys = []
    for k in [m.get("file_key"), m.get("name"), m.get("github")]:
        if k:
            nk = _norm_token(k)
            if nk not in keys:
                keys.append(nk)
    return keys

def _split_tokens(base_noext: str) -> Set[str]:
    toks = re.split(r"[\s_\-\.]+", _norm_token(base_noext))
    return set(t for t in toks if t)

def _path_tokens_without_ext(path: str) -> Set[str]:
    """ê²½ë¡œì˜ ëª¨ë“  ì»´í¬ë„ŒíŠ¸(í™•ì¥ì ì œì™¸)ì—ì„œ í† í° ì¶”ì¶œ."""
    parts = []
    for seg in path.replace("\\", "/").split("/"):
        if not seg:
            continue
        base, _ext = os.path.splitext(seg)
        if base:
            parts.append(base)
    toks = set()
    for p in parts:
        toks |= _split_tokens(p)
    return toks

def _member_owns_path(path: str, pid: int, member: dict) -> bool:
    """
    ì œì¶œ íŒŒì¼ ì—¬ë¶€(ê²¬ê³  ë²„ì „):
      - ê²½ë¡œ(ì •ê·œí™”) ì•ˆì— 'boj_{pid}'ê°€ ìˆì–´ì•¼ í•¨
      - ì½”ë“œ íŒŒì¼ í™•ì¥ìì—¬ì•¼ í•¨
      - íŒŒì¼ëª…(í™•ì¥ì ì œì™¸)ì— ë©¤ë²„ key( file_key / name / github ì¤‘ í•˜ë‚˜ )ê°€ í¬í•¨ë˜ë©´ DURING
      - ì¶”ê°€: ë””ë ‰í„°ë¦¬ ê²½ë¡œì—ë„ ë©¤ë²„ key í† í°ì´ ë‹¨ë…ìœ¼ë¡œ ë“±ì¥í•˜ë©´ ì¸ì •
    """
    p = path.replace("\\", "/")
    base = os.path.basename(p)
    base_noext, ext = os.path.splitext(base)
    if ext.lower() not in ALLOWED_EXT:
        return False

    pid_s = str(pid)
    klist = _member_keys_for_match(member)  # ['keehoon', 'noone_is_hier', ...]

    bn_norm = _norm_token(base_noext)  # êµ¬ë¶„ì í†µì¼(ëŒ€/ì†Œë¬¸ì, -, _ ë“±)
    # 1) íŒŒì¼ëª… íŒ¨í„´ í™•ì • ë§¤ì¹˜: <key>_(or -)<pid>(...)
    # ê·œì¹™ A: <name>_<pid>[_suffix]  (ì •í™• ì¼ì¹˜)
    for k in klist:
        if re.match(rf"^{re.escape(k)}_{pid_s}(?:_.+)?$", bn_norm):
            return True

    # ê·œì¹™ B: boj_<pid>_<name>  (ì •í™• ì¼ì¹˜)
    for k in klist:
        if re.match(rf"^boj_{pid_s}_{re.escape(k)}(?:_.+)?$", bn_norm):
            return True

    # 2) ë””ë ‰í„°ë¦¬ êµ¬ì¡° íŒíŠ¸: .../boj_<pid>.../ <basename startswith key>
    if re.search(rf"/boj_{pid_s}[^/]*/", p):
        for k in klist:
            if bn_norm.startswith(k + "_") or bn_norm.startswith(k + "-") or k in _split_tokens(base_noext):
                return True

    # 3) ë³´ì¡° ê·œì¹™(ëŠìŠ¨): ê²½ë¡œ í† í° ì–´ë”˜ê°€ì— pidì™€ keyê°€ ê³µì¡´
    all_toks = _path_tokens_without_ext(p)
    if (pid_s in all_toks) and any(k in all_toks for k in klist):
        return True

    return False

# ---------- Filename â†’ (pid, seat) helper (global) ----------
def _parse_pid_and_seat_from_basename(base_noext: str,
                                      participants,
                                      assigned_universe: Set[int]) -> Tuple[int | None, str | None]:
    """
    íŒŒì¼ëª…ì—ì„œ PIDì™€ seat ì¶”ì •
      - ê·œì¹™ A: <name...>_<pid>(_<suffix>)?
      - ê·œì¹™ B: boj_<pid>_<name...>
    name/í† í° ë¹„êµëŠ” normalizeëœ í† í° ë‹¨ìœ„ë¡œ ìˆ˜í–‰
    """
    bn = _norm_token(base_noext)

    # ê·œì¹™ B: boj_<pid>_<name...>
    m = re.match(r"^boj_(\d{3,6})_(.+)$", bn)  # (.) â†’ (.+)ë¡œ ìˆ˜ì •
    if m:
        try:
            pid = int(m.group(1))
        except Exception:
            pid = None
        name_part = m.group(2)
        name_tokens = set(name_part.split("_"))
        # seat ì¶”ì •
        for mm in participants:
            seat = str(mm["seat"])
            for k in _member_keys_for_match(mm):
                if k in name_tokens:
                    return (pid if (pid in assigned_universe) else None, seat)
        return (pid if (pid in assigned_universe) else None, None)

    # ê·œì¹™ A: <name...>_<pid>(_<suffix>)?
    m = re.match(r"^(.+?)_(\d{3,6})(?:_.+)?$", bn)
    if m:
        name_part = m.group(1)
        try:
            pid = int(m.group(2))
        except Exception:
            pid = None
        name_tokens = set(name_part.split("_"))
        for mm in participants:
            seat = str(mm["seat"])
            for k in _member_keys_for_match(mm):
                if k in name_tokens:
                    return (pid if (pid in assigned_universe) else None, seat)
        return (pid if (pid in assigned_universe) else None, None)

    return (None, None)

# ---------- Git helpers ----------
+import subprocess, shlex, unicodedata

# ---------- Robust subprocess helpers (bytes + multi-decoding) ----------
def _run_bytes(cmd: str, cwd: str = ROOT_DIR) -> bytes:
    p = subprocess.Popen(cmd, shell=True, cwd=cwd,
                         stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)
    out, _ = p.communicate()
    return out or b""

def _decode_git(b: bytes) -> str:
    for enc in ("utf-8", "cp949", "euc-kr", "latin-1"):
        try:
            return b.decode(enc)
        except Exception:
            continue
    return b.decode("utf-8", errors="replace")

def _run(cmd: str, cwd: str = ROOT_DIR) -> str:
    # bytes ìˆ˜ì§‘ í›„ ë‹¤ì¤‘ ì¸ì½”ë”© í´ë°±ìœ¼ë¡œ ì•ˆì „ ë””ì½”ë”©
    return _decode_git(_run_bytes(cmd, cwd))

def _clean_git_path(s: str) -> str:
    """gitì´ C-quotedë¡œ ë‚´ë³´ë‚¸ ê²½ë¡œë¥¼ ì •ë¦¬(ì–‘ë ë”°ì˜´í‘œ ì œê±°)"""
    if not s:
        return s
    s = s.strip()
    if len(s) >= 2 and s[0] == '"' and s[-1] == '"':
        s = s[1:-1]
    return s

def list_all_refs() -> List[str]:
    if not CHECK_BRANCHES:
        return ["HEAD", "main", "origin/main"]
    refs = []
    try:
        out1 = _run("git for-each-ref --format='%(refname:short)' refs/heads/")
        out2 = _run("git for-each-ref --format='%(refname:short)' refs/remotes/")
        refs = [ln.strip().strip("'") for ln in (out1 + out2).splitlines() if ln.strip()]
    except Exception:
        refs = ["HEAD", "main", "origin/main"]
    # ì¤‘ë³µ ì œê±°, main/HEAD ìš°ì„ 
    order = []
    seen = set()
    for r in ["HEAD", "main", "origin/main"]:
        if r not in seen:
            order.append(r); seen.add(r)
    for r in refs:
        if r not in seen:
            order.append(r); seen.add(r)
    if DEBUG:
        print(f"[debug] refs detected: {len(order)} -> {', '.join(order[:12])}{' ...' if len(order)>12 else ''}")
    return order

def infer_problems_root(weeks_cfg) -> str:
    # e.g. "problems/week04/README.md" -> "problems"
    for w in weeks_cfg:
        p = (w.get("path") or "").strip()
        if p:
            parts = p.replace("\\","/").split("/")
            if len(parts) >= 2:
                return parts[0]
    return "problems"

def list_paths_in_ref(ref: str, rel_path: str) -> List[str]:
    try:
        cmd = (
            f"git -c core.quotepath=off ls-tree -r --name-only "
            f"{shlex.quote(ref)} -- {shlex.quote(rel_path)}"
        )
        out = _run(cmd) # ë‚´ë¶€ì ìœ¼ë¡œ bytesâ†’decode í´ë°±
        return [_clean_git_path(ln.strip()) for ln in out.splitlines() if ln.strip()]
    except Exception:
        return []

def paths_in_refs(refs: List[str], rel_path: str) -> List[str]:
    seen, out = set(), []
    for r in refs:
        for p in list_paths_in_ref(r, rel_path):
            if p not in seen:
                seen.add(p); out.append(p)
    return out

def _resolve_main_ref() -> str:
    for ref in ["origin/main", "main", "HEAD"]:
        try:
            out = _run(f"git rev-parse --verify {shlex.quote(ref)}")
            if out.strip():
                return ref
        except Exception:
            continue
    return "HEAD"

def list_diff_paths_vs_main(ref_head: str, rel_path: str) -> List[str]:
    base = _resolve_main_ref()
    try:
        cmd = (
            f"git -c core.quotepath=off diff --name-only "
            f"{shlex.quote(base)}...{shlex.quote(ref_head)} -- {shlex.quote(rel_path)}"
        )
        out = _run(cmd)
        return [_clean_git_path(ln.strip()) for ln in out.splitlines() if ln.strip()]
    except Exception:
        return []

# ---------- Submit commit scanning (MAIN ONLY, robust) ----------
SUBMIT_RE = re.compile(
    r"""submit\s*[:\]\uff1a]?\s*week\s*0*([0-9]{1,2})\s*[-â€“â€”_ ]\s*([A-Za-z0-9_\-]+)""",
    re.IGNORECASE | re.VERBOSE,
)

def collect_submit_commits_on_main(limit_env_var: str = "ALSS_LOG_LIMIT") -> List[Tuple[str, str, List[str]]]:
    """
    main íˆìŠ¤í† ë¦¬ì—ì„œ 'submit: week{ë²ˆí˜¸}-{alias}' ì»¤ë°‹ë§Œ ìˆ˜ì§‘.
    ë°˜í™˜: [(sha, subject(NFKC), [changed_paths...])], ìµœì‹ ìˆœ
    """
    ref = _resolve_main_ref()
    parts = [
        "git", "-c", "core.quotepath=off",
        "-c", "i18n.logOutputEncoding=UTF-8",
        "log", "--no-color",
    ]
    try:
        lim = int(os.getenv(limit_env_var, "").strip() or "0")
        if lim > 0:
            parts += ["-n", str(lim)]
    except Exception:
        pass
    # ì œëª©ë§Œìœ¼ë¡œë„ ë§¤ì¹­ë˜ì§€ë§Œ, í¬ë§·ì€ ê¹”ë”í•˜ê²Œ ìœ ì§€
    parts += [f"--pretty=format:%H%x1f%ct%x1f%s%x1e", ref]
    cmd = " ".join(shlex.quote(x) for x in parts)

    raw_b = _run_bytes(cmd)
    raw = _decode_git(raw_b)
    recs = raw.split("\x1e")
    out: List[Tuple[str, str, List[str]]] = []

    for rec in recs:
        if not rec.strip():
            continue
        cols = rec.split("\x1f")
        if len(cols) < 3:
            continue
        sha, _ts, subj = cols[0].strip(), cols[1].strip(), cols[2].strip()
        subj_norm = unicodedata.normalize("NFKC", subj)
        if not SUBMIT_RE.search(subj_norm):
            continue

        # í•´ë‹¹ ì»¤ë°‹ì˜ ë³€ê²½ íŒŒì¼ (merge ì•ˆì „)
        try:
            files_b = _run_bytes(" ".join([
                "git", "-c", "core.quotepath=off",
                "diff-tree", "--no-commit-id", "--name-only", "-r",
                "-m", "--first-parent", shlex.quote(sha),
            ]))
            files = _decode_git(files_b)
            paths = [_clean_git_path(p.strip()) for p in files.splitlines() if p.strip()]
        except Exception:
            paths = []
        out.append((sha, subj_norm, paths))

    if DEBUG:
        print(f"[debug] submit commits parsed on {ref}: {len(out)}")

    return out

# ---------- Repo scanning: GLOBAL index (across all weeks/branches) ----------
def collect_repo_files_all(weeks_cfg, refs: List[str]) -> Dict[int, List[str]]:
    """
    ëª¨ë“  refsì—ì„œ problems/ ì´í•˜ íŒŒì¼ì„ ëª¨ì•„ pid -> [paths...] ë§¤í•‘
    """
    problems_root = infer_problems_root(weeks_cfg)
    paths = paths_in_refs(refs, problems_root)
    by_pid: Dict[int, List[str]] = {}
    for p in paths:
        m = re.search(r"boj_(\d+)", p)
        if not m:
            continue
        # â¬‡â¬‡â¬‡ ì¶”ê°€: ì†ŒìŠ¤ í™•ì¥ìë§Œ ìˆ˜ì§‘
        ext = os.path.splitext(p)[1].lower()
        if ext not in ALLOWED_EXT:
            continue
        pid = int(m.group(1))
        by_pid.setdefault(pid, []).append(p)
    return by_pid

# ---------- DURING/PRE classification (repo-backed) ----------
def classify_states_repo(week_cfg, members, problems: List[int], repo_index_all: Dict[int, List[str]]) -> Dict[int, Dict[str, str]]:
    """
    DURING: solved_by AND (repo(any ref, any week dir) has member file)
    PRE   : solved_by AND (repoì— íŒŒì¼ ì—†ìŒ)
    NONE  : solved_by ì•„ë‹˜
    """
    pset = set(problems)
    results = {pid: {} for pid in problems}

    for m in members:
        seat = str(m["seat"])
        handle = m["solved_handle"]
        solved = solved_set(handle, restrict_ids=pset)
        if DEBUG:
            print(f"[debug] {handle} week={week_cfg['id']} solved={len(solved)} / assigned={len(pset)}")
        for pid in problems:
            if pid not in solved:
                results[pid][seat] = "NONE"; continue
            owned = any(_member_owns_path(path, pid, m) for path in repo_index_all.get(pid, []))
            if DEBUG and pid in solved:
                cand = repo_index_all.get(pid, [])
                print(f"[debug] DURING-check seat={seat} handle={handle} pid={pid} cand={len(cand)} -> {'DURING' if owned else 'PRE'}")
                if cand and not owned:
                    for p in cand[:6]:
                        ok = _member_owns_path(p, pid, m)
                        print(f"         try: member={m.get('file_key') or m.get('name') or m.get('github')} vs {p} => {ok}")
            results[pid][seat] = "DURING" if owned else "PRE"
    return results

# ---------- Submission week attribution ----------
def build_submission_attribution(weeks_cfg, participants, states_bundle=None) -> Dict[str, Dict[int, str]]:
    """
    ë°˜í™˜: { seat(str) : { pid(int) : week_label("02","03",...) } }
    ìš°ì„ ìˆœìœ„: mainì˜ submit ì»¤ë°‹ ì œëª© â†’ (ë³´ì¡°) í˜„ì¬ ì£¼ì°¨ ë¸Œëœì¹˜ diff â†’ (ì˜µì…˜) DURING í´ë°±
    """
    problems_root = infer_problems_root(weeks_cfg)

    # ì œì¶œ íŒŒì¼ì—ì„œ PIDë¥¼ ì¶”ì¶œí•  ë•Œ 'ë°°ì • ì„¸íŠ¸ ë‚´ PIDë§Œ' ì§‘ê³„í•˜ê¸° ìœ„í•´
    # ì „ ì£¼ì°¨ì˜ ë°°ì • PID ìœ ë‹ˆë²„ìŠ¤ë¥¼ ë¯¸ë¦¬ ë§Œë“ ë‹¤.
    assigned_universe: Set[int] = set()
    for w in weeks_cfg:
        for g in (w.get("groups") or []):
            for pid in g.get("problems", []):
                assigned_universe.add(pid)

    # seat ì¸ë±ìŠ¤ (alias/branch_key/file_key/name/github â†’ seat)
    seat_by_branch_key = {}
    for m in participants:
        seat = str(m["seat"])
        for key in [m.get("branch_key"), m.get("file_key"), m.get("name"), m.get("github")]:
            if key:
                seat_by_branch_key[_norm_token(key)] = seat
    if DEBUG:
        print("[debug] seat_by_branch_key:", seat_by_branch_key)

    # 1) mainì˜ submit ì»¤ë°‹ ê¸°ë°˜ ê·€ì†
    commit_attrib: Dict[str, Dict[int, str]] = {}
    submit_commits = collect_submit_commits_on_main()

    for sha, subj, files in reversed(submit_commits):
        mm = SUBMIT_RE.search(subj)  # ì˜ˆ: submit: week03-jinyeop
        if not mm:
            continue
        wk_lab = f"{int(mm.group(1)):02d}"
        alias_key = _norm_token(mm.group(2))
        alias_seat = seat_by_branch_key.get(alias_key)

        for p in files:
            pp = p.replace("\\", "/")
            if problems_root + "/" not in pp:
                continue
            # ë¬¸ì œ ì†ŒìŠ¤ë§Œ ì§‘ê³„
            ext = os.path.splitext(pp)[1].lower()
            if ext not in ALLOWED_EXT:
                continue
            base_noext = os.path.splitext(os.path.basename(pp))[0]
            pid, seat_from_name = _parse_pid_and_seat_from_basename(base_noext, participants, assigned_universe)
            if pid is None:
                # boj_ ë””ë ‰í† ë¦¬ëª… ë“± ë³´ì¡°: path ì „ì²´ì—ì„œ boj_<pid>
                m_dir = re.search(r"boj_(\d{3,6})", pp)
                if m_dir:
                    try:
                        cand = int(m_dir.group(1))
                        if cand in assigned_universe:
                            pid = cand
                    except Exception:
                        pass
            if pid is None:
                continue

            # seat ìš°ì„ ìˆœìœ„: PR ì œëª©(alias) > íŒŒì¼ëª… ì¶”ì • seat > (ì—†ìœ¼ë©´ ìŠ¤í‚µ)
            final_seat = alias_seat or seat_from_name
            if not final_seat:
                # ë§ˆì§€ë§‰ ë³´ì¡°: ê²½ë¡œ ê·œì¹™(ë“œë¬¼ê²Œ ì´ë¦„ì´ ë¹ ì§„ ê²½ìš°)
                for mmbr in participants:
                    if _member_owns_path(pp, pid, mmbr):
                        final_seat = str(mmbr["seat"])
                        break
            if not final_seat:
                continue

            seat_map = commit_attrib.setdefault(final_seat, {})
            if pid not in seat_map:            # first submit wins
                seat_map[pid] = wk_lab
            if DEBUG:
                print(f"[debug][submit] sha={sha[:8]} week={wk_lab} seat={final_seat} pid={pid} file={os.path.basename(pp)}")

    # 2) (ë³´ì¡°) ì§„í–‰ ì¤‘ ì£¼ì°¨ì˜ ë¸Œëœì¹˜ diff ê¸°ë°˜ ë³´ì •
    # í˜„ì¬ ì£¼ì°¨ ë¼ë²¨(ìˆ«ì id ìµœëŒ€ê°’)ë§Œ ë³´ì • ëŒ€ìƒìœ¼ë¡œ ì‚¬ìš©
    numeric_labels = [int(str(w.get("id"))) for w in weeks_cfg if str(w.get("id")).isdigit()]
    current_wk_lab = f"{max(numeric_labels):02d}" if numeric_labels else None

    def _ref_unix_ts(ref: str) -> int:
        try:
            out = _run(f"git log -1 --format=%ct {shlex.quote(ref)}")
            return int(out.strip() or "0")
        except Exception:
            return 0

    refs = list_all_refs()
    week_branch_re = re.compile(r"week\s*(\d+)-([A-Za-z0-9_\-]+)", re.IGNORECASE)

    best_branch: Dict[Tuple[str, int], Tuple[int, str, str]] = {}  # -> (ts, wk_lab, ref)

    for r in refs:
        mb = week_branch_re.search(r)
        if not mb:
            continue
        wk_lab = f"{int(mb.group(1)):02d}"     # âœ… ê³¼ê±° ì£¼ì°¨ë„ ë³´ì • í—ˆìš©
        bkey = _norm_token(mb.group(2))
        seat = seat_by_branch_key.get(bkey)
        if not seat:
            continue

        ts = _ref_unix_ts(r)
        ps = list_diff_paths_vs_main(r, problems_root)
        if DEBUG:
            print(f"[debug] branch={r} week={wk_lab} diff_paths={len(ps)} (problems under)")

        member = next((mm for mm in participants if str(mm["seat"]) == seat), None)
        for p in ps:
            m2 = re.search(r"boj_(\d+)", p)
            if not m2:
                continue
            pid = int(m2.group(1))
            if pid not in assigned_universe:   # âœ… ë°°ì • ë¬¸ì œë§Œ ê·€ì†
                continue
            if member and _member_owns_path(p, pid, member):
                key = (seat, pid)
                prev = best_branch.get(key)
                if (prev is None) or (ts > prev[0]):
                    best_branch[key] = (ts, wk_lab, r)
                if DEBUG:
                    print(f"[debug] branch-attr seat={seat} pid={pid} week={wk_lab} ref={r} ts={ts}")

    branch_attrib: Dict[str, Dict[int, str]] = {}
    for (seat, pid), (_ts, wk_lab, _ref) in best_branch.items():
        branch_attrib.setdefault(seat, {})[pid] = wk_lab

    # 3) ë³‘í•© (commit > branch-diff > DURING fallback)
    out: Dict[str, Dict[int, str]] = {str(m["seat"]): {} for m in participants}

    # 1ìˆœìœ„: ì»¤ë°‹
    for seat, mp in commit_attrib.items():
        out[seat].update(mp)

    # 2ìˆœìœ„: ì§„í–‰ ì¤‘ ë¸Œëœì¹˜ ë³´ì • (ì´ë¯¸ ì»¤ë°‹ìœ¼ë¡œ ì¡íŒ pidëŠ” ìœ ì§€)
    for seat, mp in branch_attrib.items():
        for pid, wk_lab in mp.items():
            out[seat].setdefault(pid, wk_lab)

    # 3ìˆœìœ„: DURING í´ë°±(ì˜µì…˜)
    if ALSS_TREND_FALLBACK_DURING and states_bundle:
        for w in weeks_cfg:
            if not (w.get("groups") or []):
                continue
            lab = f"{int(w['id']):02d}" if str(w.get("id", "")).isdigit() else str(w.get("id", ""))
            for g in w["groups"]:
                for pid, seat_states in states_bundle[w["id"]][g["key"]].items():
                    for m in participants:
                        seat = str(m["seat"])
                        if pid not in out[seat] and seat_states.get(seat) == "DURING":
                            out[seat][pid] = lab

    if DEBUG:
        total_mapped = sum(len(v) for v in out.values())
        print(f"[debug] submission_attribution mapped pairs: {total_mapped}")
        print("[debug] per-seat counts:", {s: len(mp) for s, mp in out.items()})
    return out

# ---------- Root README dashboards ----------
def replace_block(text: str, marker: str, new_md: str) -> str:
    start = f"<!--START:{marker}-->"
    end   = f"<!--END:{marker}-->"
    pat = re.compile(re.escape(start) + r".*?" + re.escape(end), flags=re.DOTALL)
    rep = f"{start}\n\n{new_md}\n\n{end}"
    if pat.search(text):
        return pat.sub(rep, text)
    return text.strip() + "\n\n" + rep + "\n"

def wk_label(w) -> str:
    try:
        return f"{int(w['id']):02d}"
    except Exception:
        return str(w.get('id','?'))

def render_root_dashboards(root_readme_path: str, participants, weeks_cfg, states_bundle):
    # 1) ì£¼ì°¨ë³„ ì„¸íŠ¸/íƒ€ì´í‹€
    week_sets: List[Set[int]] = []
    week_titles: List[str] = []
    solved_by_member_per_week: List[Dict[str, Set[int]]] = []

    for w in weeks_cfg:
        pids = set(pid for g in w["groups"] for pid in g["problems"])
        week_sets.append(pids)
        week_titles.append(wk_label(w))

        solved_map: Dict[str, Set[int]] = {}
        for m in participants:
            seat = str(m["seat"])
            solved = set()
            for g in w["groups"]:
                for pid, seat_states in states_bundle[w["id"]][g["key"]].items():
                    # DURINGë§Œ ì§‘ê³„
                    if seat_states[seat] == "DURING":
                        solved.add(pid)
            solved_map[seat] = solved
        solved_by_member_per_week.append(solved_map)

    # ì£¼ì°¨ë³„ ë°°ì • ì§‘í•© (ê·¸ ì£¼ì°¨ "ë‹¨ì¼" ì„¸íŠ¸)
    assign_by_lab: Dict[str, Set[int]] = {}
    for w in weeks_cfg:
        lab = wk_label(w)
        ws = set(pid for g in w["groups"] for pid in g["problems"])
        assign_by_lab[lab] = ws

    # 2) ì œì¶œ ì£¼ì°¨ ê·€ì† ë§µ
    submission_map = build_submission_attribution(
        weeks_cfg, participants,
        states_bundle if ALSS_TREND_FALLBACK_DURING else None
    )

    # 3-1) ì£¼ì°¨ë³„ ì™„ë£Œìœ¨ (%): DURINGë§Œ
    def week_matrix_md():
        header = ["ì£¼ì°¨ï¼¼ë©¤ë²„"] + [m["name"] for m in participants] + ["í•©ê³„(%)"]
        lines = ["| " + " | ".join(header) + " |",
                "|" + "---|" * (len(header)-1) + "---|"]
        col_tot_solved = [0]*len(participants)
        col_tot_assign = [0]*len(participants)

        for widx, ws in enumerate(week_sets):
            assign = len(ws)
            w_cfg = weeks_cfg[widx] if widx < len(weeks_cfg) else {}
            if assign == 0:
                if DEBUG and not (w_cfg.get("groups") or []):
                    print(f"[debug] week {w_cfg.get('id')} has no groups (dummy week)")
                continue  # ë”ë¯¸(ë°°ì • 0) ì£¼ì°¨ëŠ” ì™„ë£Œìœ¨ í‘œì—ì„œ ìˆ¨ê¹€

            row = [week_titles[widx]]
            row_sum = 0
            for mi, m in enumerate(participants):
                seat = str(m["seat"])
                solved = len(solved_by_member_per_week[widx][seat] & ws)
                row_sum += solved
                col_tot_solved[mi] += solved
                col_tot_assign[mi] += assign
                rate = round(solved / assign * 100) if assign else 0
                row.append(str(rate))
            row.append(str(round(row_sum / (assign*len(participants)) * 100)))
            lines.append("| " + " | ".join(row) + " |")

        tot = ["í•©ê³„(%)"]
        for mi in range(len(participants)):
            rate = round(col_tot_solved[mi] / col_tot_assign[mi] * 100) if col_tot_assign[mi] else 0
            tot.append(str(rate))
        overall = round(sum(col_tot_solved) / sum(col_tot_assign) * 100) if sum(col_tot_assign) else 0
        tot.append(str(overall))
        # â¬‡ ì‹¤ì œë¡œ í•©ê³„ í–‰ì„ í‘œì— ì¶”ê°€
        lines.append("| " + " | ".join(tot) + " |")
        return "\n".join(lines)

    # 3-2) ì „ì²´ ë¦¬ë”ë³´ë“œ (ëˆ„ì ): DURINGë§Œ (ìœ ë‹ˆí¬ PID ê¸°ì¤€)
    def leaderboard_md():
        assigned_universe = set()
        for ws in week_sets:
            assigned_universe |= ws
        assigned_total = len(assigned_universe)

        scores = []
        for m in participants:
            seat = str(m["seat"])
            solved_union = set()
            for widx, ws in enumerate(week_sets):
                solved_union |= (solved_by_member_per_week[widx][seat] & ws)
            scores.append((m["name"], len(solved_union)))

        scores.sort(key=lambda x: x[1], reverse=True)
        lines = ["### ì „ì²´ ë¦¬ë”ë³´ë“œ (ëˆ„ì )"]
        for i, (name, sc) in enumerate(scores, 1):
            rate = round(sc / assigned_total * 100) if assigned_total else 0
            lines.append(f"{i}) {name} â€” **{sc}/{assigned_total} ({rate}%)**")
        return "\n".join(lines)
    
    # 3-3) ë©¤ë²„ë³„ ì£¼ì°¨ë³„ ëˆ„ì  ì¶”ì„¸ (ì œì¶œ ì£¼ì°¨ ê·€ì† / ë°°ì • ëˆ„ì , %)
    def trend_md():

        if DEBUG:
            # ì£¼ì°¨ë³„ DURING ëˆ„ì (ground truth)
            during_cumu = {}
            seen = set()
            labs = [wk_label(w) for w in weeks_cfg]
            for i, lab in enumerate(labs):
                U = set().union(*[set(pid for g in weeks_cfg[j]["groups"] for pid in g["problems"])
                                for j in range(i+1)])
                row = {}
                for m in participants:
                    seat = str(m["seat"])
                    seen |= set(pid for w in weeks_cfg[:i+1]
                                for g in w["groups"]
                                for pid, st in states_bundle[w["id"]][g["key"]].items()
                                if st[seat] == "DURING")
                    row[seat] = len([p for p in seen if p in U])
                during_cumu[lab] = row
            print("[debug] DURING cumu:", during_cumu)

        # 1) ì œì¶œ ê·€ì†ì—ì„œ ë‚˜ì˜¨ ì£¼ì°¨ ë¼ë²¨ ìˆ˜ì§‘
        labels_from_submission = {wk for seat_map in submission_map.values() for wk in seat_map.values()}

        # 2) ë¼ë²¨ ì •ë ¬ í‚¤(ìˆ«ìëŠ” 2ìë¦¬ '03'ì²˜ëŸ¼ ì •ìˆ˜ë¡œ ì •ë ¬, ê·¸ ì™¸ëŠ” ì‚¬ì „ì‹)
        def _wk_key(s):
            s = str(s)
            return (0, int(s)) if re.fullmatch(r"\d+", s) else (1, s)

        # 3) í‘œ í–‰ ë¼ë²¨ = ë°°ì • ì£¼ì°¨ âˆª ê·€ì† ì£¼ì°¨
        all_labels = sorted(set(week_titles) | labels_from_submission, key=_wk_key)
        label_pos = {lab: i for i, lab in enumerate(all_labels)}

        # 4) ë¶„ëª¨(ë°°ì • ëˆ„ì  ì§‘í•©)ë¥¼ all_labels ìˆœì„œì— ë§ê²Œ êµ¬ì„±
        cumulative_assign_sets_all = []
        for i, lab in enumerate(all_labels):
            U = set()
            for wl, ws in zip(week_titles, week_sets):
                if label_pos[wl] <= i:  # ë°°ì • ì£¼ì°¨ê°€ í˜„ì¬ ë¼ë²¨ ì´ì „/ë™ì¼ì´ë©´ í¬í•¨
                    U |= ws
            cumulative_assign_sets_all.append(U)

        # 5) í‘œ ë Œë”ë§
        header = ["ì£¼ì°¨ï¼¼ë©¤ë²„"] + [m["name"] for m in participants]
        lines = ["| " + " | ".join(header) + " |",
                "|" + "---|" * (len(header)-1) + "---|"]

        for i, (lab, U) in enumerate(zip(all_labels, cumulative_assign_sets_all)):
            denom = len(U)
            row = [lab]
            for m in participants:
                seat = str(m["seat"])
                mp = submission_map.get(seat, {})
                # ê·€ì† ì£¼ì°¨ê°€ í˜„ì¬ ë¼ë²¨ ì´í•˜ì¸ ì œì¶œ ê±´ ëˆ„ì 
                solved = sum(
                    1
                    for pid, wk_lab in mp.items()
                    if (pid in U) and (wk_lab in label_pos) and (label_pos[wk_lab] <= i)
                )
                rate = round(solved / denom * 100) if denom else 0
                row.append(f"{solved}/{denom} ({rate})")
            lines.append("| " + " | ".join(row) + " |")

        return "\n".join(
            ["### ë©¤ë²„ë³„ ì£¼ì°¨ë³„ ëˆ„ì  ì¶”ì„¸ (ì œì¶œ ì£¼ì°¨ ê·€ì† / ë°°ì • ëˆ„ì , %)"] + lines
        )
    
    text = read_file(root_readme_path)
    text = replace_block(text, "DASHBOARD_WEEKS", "\n".join(["### ì£¼ì°¨ë³„ ì™„ë£Œìœ¨ (%)", week_matrix_md()]))
    text = replace_block(text, "DASHBOARD_LEADERBOARD", leaderboard_md())
    text = replace_block(text, "DASHBOARD_TREND", trend_md())
    write_if_changed(root_readme_path, text)
    return True

# ---------- main ----------
def main():
    participants = load_yaml(PARTICIPANTS_YAML)["members"]
    weeks_cfg = load_yaml(WEEKS_YAML)["weeks"]
    participants = sorted(participants, key=lambda m: m["seat"])

    # ì „ ë¸Œëœì¹˜/ë¦¬ëª¨íŠ¸ í™•ë³´ ì „ì œ: Actionsì—ì„œ git fetch --all --prune --tags ìˆ˜í–‰ ê¶Œì¥
    refs = list_all_refs()
    repo_index_all = collect_repo_files_all(weeks_cfg, refs)
    if DEBUG:
        target_pids_dbg = sorted({pid for w in weeks_cfg for g in w["groups"] for pid in g["problems"]})
        print(f"[debug] target_pids (weeks.yaml): {len(target_pids_dbg)}")
        for pid in target_pids_dbg[:30]:
            paths = repo_index_all.get(pid, [])
            print(f"[debug] pid={pid} candidates={len(paths)}")
            for p in paths[:8]:
                print("        -", p)

    # Week READMEs
    states_bundle = {}  # week_id -> group_key -> {pid -> {seat -> 'PRE'|'DURING'|'NONE'}}
    for w in weeks_cfg:
        w_id = w["id"]
        states_bundle[w_id] = {}
        for g in w["groups"]:
            states = classify_states_repo(w, participants, g["problems"], repo_index_all)
            states_bundle[w_id][g["key"]] = states
        # ë©¤ë²„ ì—´ë§Œ íŒ¨ì¹˜
        render_week_readme_members_only(w, participants, states_bundle[w_id])

    # Root README dashboards
    render_root_dashboards(ROOT_README, participants, weeks_cfg, states_bundle)

if __name__ == "__main__":
    main()
