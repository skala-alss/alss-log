#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
READMEì˜ ğŸ“ ë§í¬ â†’ í´ë”/.gitkeep ìƒì„±
READMEì˜ ë§ˆì»¤ ë¸”ë¡(<!--START:PROGRESS:...-->/<!--END:...-->) â†’ ë¬¸ì œ ë²ˆí˜¸ ì¶”ì¶œ â†’ config/weeks.yaml ë³‘í•© ê°±ì‹ 

ì‚¬ìš© ì˜ˆ:
  # ëª¨ë“  ì£¼ì°¨ README ìŠ¤ìº” + í´ë”/ì£¼ì°¨ YAML ìƒì„±/ë³‘í•©
  python scripts/gen_folders_and_weeks.py --scan-all --problems-root problems --weeks-yaml config/weeks.yaml -v

  # íŠ¹ì • READMEë§Œ ì²˜ë¦¬
  python scripts/gen_folders_and_weeks.py --readme problems/week02/README.md --weeks-yaml config/weeks.yaml -v

ì˜µì…˜:
  --no-weeks-yaml   : í´ë”/ .gitkeepë§Œ ìƒì„±í•˜ê³  weeks.yamlì€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ
  --dry-run         : ìƒì„±/ì“°ê¸° ì—†ì´ ë™ì‘ë§Œ ì‹œë®¬ë ˆì´íŠ¸
  -v / -vv          : ìƒì„¸ ë¡œê·¸
"""

from __future__ import annotations
import argparse, re, sys, unicodedata
from pathlib import Path, PurePosixPath
from urllib.parse import unquote
import yaml

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê³µí†µ ìœ í‹¸ (ê¸°ì¡´ make_gitkeep ë¡œì§ ìœ ì§€)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_FORBID_MAP = {"/":"ï¼","\\":"ï¼¼","?":"ï¼Ÿ",":":"ï¼š","*":"ï¼Š","\"":"ï¼‚","<":"ï¼œ",">":"ï¼","|":"ï½œ"}
_RESERVED_WIN = re.compile(r"^(CON|PRN|AUX|NUL|COM[1-9]|LPT[1-9])$", re.IGNORECASE)
_ZWS_RE = re.compile(r"[\u200B\u200C\u200D\uFEFF]")

MD_LINK_RE = re.compile(r"""
    \[([^\]]+)\]\s*\(
      \s*(?:<([^>]+)>\s*|((?:[^()\\]|\\.)+))\s*
    \)
""", re.VERBOSE)
HTML_LINK_RE = re.compile(r'<a\s+[^>]*href="([^"]+)"[^>]*>(.*?)</a>', re.IGNORECASE | re.DOTALL)

START_RE = re.compile(r'<!--\s*START\s*:\s*([A-Z0-9_:\-]+)\s*-->', re.IGNORECASE)
END_RE   = re.compile(r'<!--\s*END\s*:\s*([A-Z0-9_:\-]+)\s*-->',   re.IGNORECASE)
TAG_RE   = re.compile(r'<!--\s*TAG\s*:\s*([A-Za-z0-9_\-]+)\s*-->', re.IGNORECASE)

def _strip_invisibles(s: str) -> str:
    s = _ZWS_RE.sub("", (s or "").replace("\xa0"," "))
    try: s = unicodedata.normalize("NFC", s)
    except Exception: pass
    return s

def sanitize_component_keep_spaces(part: str) -> str:
    s = _strip_invisibles(part or "")
    s = "".join(ch for ch in s if ord(ch) >= 32)
    for k,v in _FORBID_MAP.items(): s = s.replace(k, v)
    s = s.rstrip(" .")
    s = re.sub(r"^\.+", "", s)
    stem = (s.split(".",1)[0]).upper()
    if _RESERVED_WIN.match(stem):
        s = "_" + s
    return s or "_"

def extract_folder_links(md: str) -> list[str]:
    links = []
    # Markdown [í…ìŠ¤íŠ¸](URL)
    for text, url_angle, url_plain in MD_LINK_RE.findall(md):
        if "ğŸ“" in text:
            url = (url_angle or url_plain or "").strip()
            if url.startswith("<") and url.endswith(">"):
                url = url[1:-1].strip()
            links.append(url)
    # HTML <a href="URL">...</a>
    for url, inner in HTML_LINK_RE.findall(md):
        if "ğŸ“" in inner:
            links.append(url.strip())

    out = []
    for l in links:
        if "://" in l:        # ì™¸ë¶€ URL ì œì™¸
            continue
        out.append(_strip_invisibles(unquote(l)).rstrip("/"))
    # ìˆœì„œ ìœ ì§€ ì¤‘ë³µ ì œê±°
    seen=set(); uniq=[]
    for l in out:
        if l not in seen:
            seen.add(l); uniq.append(l)
    return uniq

def build_safe_path(base: Path, parts: tuple[str,...]) -> Path:
    p = base
    for part in parts:
        if not part or part == ".": continue
        if part == "..":
            p = p / part; continue
        p = p / sanitize_component_keep_spaces(part)
    return p

def to_abs_paths(readme_path: Path, rel_links: list[str]) -> list[Path]:
    base = readme_path.parent.resolve()
    out=[]
    for link in rel_links:
        posix = PurePosixPath(link)
        abs_p = build_safe_path(base, posix.parts).resolve()
        try: abs_p.relative_to(base)  # base ë°– íƒˆì¶œ ë°©ì§€
        except ValueError: continue
        out.append(abs_p)
    # ì •ë ¬ + ì¤‘ë³µ ì œê±°
    return sorted(set(out))

def make_dirs_and_gitkeep(targets: list[Path], dry=False, verbose:int=0) -> tuple[int,int]:
    created_gitkeep = 0
    for d in targets:
        if verbose: print(" - mkdir:", d)
        if dry:    continue
        d.mkdir(parents=True, exist_ok=True)
        gk = d / ".gitkeep"
        if not gk.exists():
            gk.touch()
            created_gitkeep += 1
    return (len(targets), created_gitkeep)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# weeks.yaml ì¶”ì¶œ/ë³‘í•©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _split_row(line: str) -> list[str]:
    if not line.strip().startswith("|"): return []
    return [c.strip() for c in line.strip().strip("|").split("|")]

def _is_sep_row(cells: list[str]) -> bool:
    return all(re.match(r"^:?-{3,}:?$", c) or c=="" for c in cells)

def _find_heading_above(lines: list[str], start_idx: int) -> str | None:
    for i in range(start_idx-1, -1, -1):
        ln = lines[i].strip()
        if re.match(r"^#{2,6}\s+", ln):   # ##, ###, ...
            return re.sub(r"^#{2,6}\s+","", ln).strip()
    return None

def parse_groups_from_readme(md: str) -> list[dict]:
    """
    READMEì—ì„œ ê° PROGRESS ë¸”ë¡ì„ ì°¾ì•„
      { key, marker, title, problems[, tag] } ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    """
    text  = md
    lines = md.splitlines()
    groups = []

    for m in START_RE.finditer(text):
        marker = m.group(1).strip()      # e.g. PROGRESS:STACK
        if not marker.upper().startswith("PROGRESS:"):
            continue
        key = marker.split(":",1)[1].strip()
        start_pos = m.end()

        e = END_RE.search(text, start_pos)
        if not e or e.group(1).strip() != marker:
            continue
        block = text[start_pos:e.start()]

        # í—¤ë”©(íƒ€ì´í‹€) ì¶”ì¶œ
        start_line_index = text[:m.start()].count("\n")
        title = _find_heading_above(lines, start_line_index) or key

        # íƒœê·¸ ì¶”ì¶œ: ë¸”ë¡ ì§ì „ ëª‡ ì¤„ + ë¸”ë¡ ë‚´ë¶€ì—ì„œ <!--TAG:...-->
        vicinity = "\n".join(lines[max(0, start_line_index-5):start_line_index]) + "\n" + block
        tag = None
        mt = TAG_RE.search(vicinity)
        if mt: tag = mt.group(1).strip()

        # í‘œì—ì„œ "ë²ˆí˜¸" ì—´ì„ ì°¾ì•„ ì •ìˆ˜ ëª¨ìœ¼ê¸°
        bl = block.strip("\n").splitlines()
        hdr_i=None
        for i, ln in enumerate(bl):
            if ln.strip().startswith("|"):
                hdr_i=i; break
        problems=[]
        if hdr_i is not None and hdr_i+1 < len(bl):
            header = _split_row(bl[hdr_i])
            number_col=None
            for idx, col in enumerate(header):
                low = col.strip().lower()
                if low in ("ë²ˆí˜¸","no","id","problem","problem id"):
                    number_col = idx; break
            for j in range(hdr_i+2, len(bl)):
                cells = _split_row(bl[j])
                if not cells or _is_sep_row(cells): 
                    continue
                if number_col is None or number_col >= len(cells): 
                    continue
                try:
                    pid = int(re.sub(r"[^\d]","", cells[number_col]))
                    problems.append(pid)
                except Exception:
                    pass

        g = {"key": key, "marker": marker, "title": title, "problems": sorted(set(problems))}
        if tag: g["tag"] = tag
        groups.append(g)

    return groups

def detect_week_id_and_relpath(readme_path: Path, problems_root="problems") -> tuple[str|int, str]:
    parts = readme_path.as_posix().split("/")
    # ìƒëŒ€ê²½ë¡œ(ë¦¬í¬ ë£¨íŠ¸ ê¸°ì¤€) ê³„ì‚°
    if problems_root in parts:
        idx = parts.index(problems_root)
        rel_path = "/".join(parts[idx:])
    else:
        rel_path = readme_path.as_posix()
    # week id íƒì§€ (week02, week2 ë“±)
    week_id = "?"
    for p in parts:
        m = re.match(r"week\s*(\d+)", p, re.IGNORECASE)
        if m:
            week_id = int(m.group(1))
            break
    return week_id, rel_path

def load_weeks(path: Path) -> dict:
    if not path.exists(): return {"weeks": []}
    with open(path, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f) or {}
    data.setdefault("weeks", [])
    return data

def save_weeks(path: Path, data: dict, dry=False):
    if dry:
        print(yaml.safe_dump(data, sort_keys=False, allow_unicode=True))
        return
    path.parent.mkdir(parents=True, exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        yaml.safe_dump(data, f, sort_keys=False, allow_unicode=True)

def upsert_weeks_item(data: dict, item: dict, verbose:int=0):
    """
    data = {"weeks":[...]}
    item = {"id": 2, "path": "...", "groups": [...]}
    - ê°™ì€ idì˜ weekê°€ ìˆìœ¼ë©´ path ê°±ì‹ 
    - ê·¸ë£¹(key)ë³„ë¡œ problems âˆª ë³‘í•©, marker/title/tag ìµœì‹ ê°’ ë°˜ì˜
    """
    weeks = data.setdefault("weeks", [])
    # week ì°¾ê¸°/ìƒì„±
    tgt = None
    for w in weeks:
        if str(w.get("id")) == str(item["id"]):
            tgt = w; break
    if tgt is None:
        tgt = {"id": item["id"], "path": item["path"], "groups": []}
        weeks.append(tgt)
    else:
        tgt["path"] = item["path"] or tgt.get("path")

    # ê·¸ë£¹ ë³‘í•©
    for g in item.get("groups", []):
        exists = None
        for gg in tgt["groups"]:
            if gg.get("key") == g["key"]:
                exists = gg; break
        if exists is None:
            tgt["groups"].append(g)
            if verbose: print(f"  + add group {g['key']} ({len(g['problems'])} pids)")
        else:
            # problems: âˆª í›„ ì •ë ¬
            merged = sorted(set((exists.get("problems") or [])) | set(g.get("problems") or []))
            exists["problems"] = merged
            # ë©”íƒ€ë°ì´í„° ìµœì‹ í™”
            for k in ("marker","title","tag"):
                if g.get(k): exists[k] = g[k]
            if verbose: print(f"  * merge group {g['key']} â†’ {len(merged)} pids")

    # week ì •ë ¬(ìˆ«ì id ìš°ì„ )
    weeks.sort(key=lambda w: int(w["id"]) if str(w.get("id","")).isdigit() else 9999)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_args():
    p = argparse.ArgumentParser(description="README â†’ í´ë”/.gitkeep + weeks.yaml ìƒì„±ê¸° (make_gitkeep ìŠˆí¼ì…‹)")
    p.add_argument("--readme", type=Path, help="ë‹¨ì¼ README ê²½ë¡œ")
    p.add_argument("--scan-all", action="store_true", help="<problems-root>/week*/README.md ì „ë¶€ ìŠ¤ìº”")
    p.add_argument("--problems-root", default="problems", help="ì£¼ì°¨ ë””ë ‰í† ë¦¬ ë£¨íŠ¸ (ê¸°ë³¸: problems)")
    p.add_argument("--weeks-yaml", type=Path, default=Path("config/weeks.yaml"), help="ì£¼ì°¨ ì •ì˜ YAML ê²½ë¡œ")
    p.add_argument("--no-weeks-yaml", action="store_true", help="weeks.yaml ê°±ì‹  ìƒëµ")
    p.add_argument("--dry-run", action="store_true", help="ì‹¤ì œ ìƒì„±/ì“°ê¸° ì—†ì´ ì ê²€ë§Œ")
    p.add_argument("--verbose", "-v", action="count", default=0)
    return p.parse_args()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# main
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    args = parse_args()

    # ìŠ¤ìº” ëŒ€ìƒ README ëª©ë¡ ìˆ˜ì§‘
    targets: list[Path] = []
    if args.scan_all:
        root = Path(".").resolve()
        targets = [p.resolve() for p in sorted(root.glob(f"{args.problems_root}/week*/README.md"))]
        if not targets:
            print(f"âš ï¸ {args.problems_root}/week*/README.md ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", file=sys.stderr)
    elif args.readme:
        if not args.readme.exists():
            print(f"âŒ README ì—†ìŒ: {args.readme}", file=sys.stderr); sys.exit(2)
        targets = [args.readme.resolve()]
    else:
        print("âŒ --scan-all ë˜ëŠ” --readme ë¥¼ ì§€ì •í•˜ì„¸ìš”.", file=sys.stderr); sys.exit(2)

    # weeks.yaml ë¡œë“œ (ë³‘í•© ëª¨ë“œ)
    weeks_data = None if args.no_weeks_yaml else load_weeks(args.weeks_yaml)

    # ê° README ì²˜ë¦¬
    for readme in targets:
        md = readme.read_text(encoding="utf-8", errors="ignore")

        # 1) ğŸ“ ë§í¬ ê¸°ë°˜ í´ë”/.gitkeep
        links = extract_folder_links(md)
        abs_targets = to_abs_paths(readme, links)
        if args.verbose:
            print(f"[{readme}] í´ë” ëŒ€ìƒ {len(abs_targets)}ê°œ")
        n_dirs, n_gk = make_dirs_and_gitkeep(abs_targets, dry=args.dry_run, verbose=args.verbose)
        if args.verbose:
            print(f" â””â”€ í´ë” ìƒì„±/í™•ì¸: {n_dirs}ê°œ, .gitkeep ì‹ ê·œ: {n_gk}ê°œ")

        # 2) PROGRESS ë¸”ë¡ â†’ weeks.yaml ë³‘í•©
        if not args.no_weeks_yaml:
            groups = parse_groups_from_readme(md)
            week_id, rel_path = detect_week_id_and_relpath(readme, problems_root=args.problems_root)
            item = {"id": week_id, "path": rel_path, "groups": groups}
            if args.verbose:
                print(f" â””â”€ weeks item: id={item['id']} path={item['path']} groups={len(groups)}")
                for g in groups:
                    print(f"    - {g['key']:8s} : {len(g['problems']):3d} pids  ({g.get('marker')})")
            upsert_weeks_item(weeks_data, item, verbose=args.verbose)

    # 3) weeks.yaml ì €ì¥
    if (weeks_data is not None) and (not args.no_weeks_yaml):
        if args.verbose:
            print(f"[write] {args.weeks_yaml}")
        if args.dry_run:
            print("----- weeks.yaml (dry-run preview) -----")
        save_weeks(args.weeks_yaml, weeks_data, dry=args.dry_run)

    print("âœ… ì™„ë£Œ")

if __name__ == "__main__":
    main()
